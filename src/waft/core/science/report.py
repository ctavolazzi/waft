"""
ManifestoGenerator: Scientific Report Generator for the Multiverse.

Generates high-fidelity Markdown reports from laboratory.jsonl and Biome state,
providing comprehensive scientific documentation of the evolutionary experiment.
"""

import json
from pathlib import Path
from typing import Dict, List, Optional, TYPE_CHECKING
from collections import defaultdict
from datetime import datetime

from .observer import TheObserver
from .taxonomy import LineagePoet

if TYPE_CHECKING:
    from ..world.biome import Biome


class ManifestoGenerator:
    """
    Generator for scientific manifestos (session reports).
    
    Aggregates data from laboratory.jsonl and current Biome state
    to create comprehensive Markdown reports.
    """
    
    def __init__(self, project_path: Path, observer: Optional[TheObserver] = None):
        """
        Initialize ManifestoGenerator.
        
        Args:
            project_path: Path to project root
            observer: TheObserver instance (creates if None)
        """
        self.project_path = Path(project_path)
        self.observer = observer or TheObserver(project_path=project_path)
    
    def generate_session_report(self, biome: Optional["Biome"] = None) -> str:
        """
        Generate comprehensive session report (The Scientific Manifesto).
        
        Args:
            biome: Optional Biome instance for current state
            
        Returns:
            Markdown-formatted report string
        """
        timestamp = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
        
        lines = []
        lines.append("# THE STATE OF THE BIOME")
        lines.append(f"**Timestamp**: {timestamp}")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Load laboratory data
        lab_data = self._load_laboratory_data()
        
        # Section 1: Current Biodiversity
        lines.extend(self._section_biodiversity(lab_data, biome))
        lines.append("")
        
        # Section 2: The Phylogenetic Tree
        lines.extend(self._section_phylogenetic_tree(lab_data))
        lines.append("")
        
        # Section 3: Metabolic Health
        lines.extend(self._section_metabolic_health(lab_data, biome))
        lines.append("")
        
        # Section 4: Breach Incidents
        lines.extend(self._section_breach_incidents(lab_data))
        lines.append("")
        
        # Footer
        lines.append("---")
        lines.append("")
        lines.append(f"*Report generated by ManifestoGenerator at {timestamp}*")
        
        return "\n".join(lines)
    
    def _load_laboratory_data(self) -> List[Dict]:
        """
        Load all events from laboratory.jsonl.
        
        Returns:
            List of event dictionaries
        """
        lab_file = self.project_path / "_pyrite" / "science" / "laboratory.jsonl"
        
        if not lab_file.exists():
            return []
        
        events = []
        with open(lab_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        event = json.loads(line)
                        events.append(event)
                    except json.JSONDecodeError:
                        continue
        
        return events
    
    def _section_biodiversity(self, lab_data: List[Dict], biome: Optional["Biome"]) -> List[str]:
        """Generate Current Biodiversity section."""
        lines = []
        lines.append("## Current Biodiversity")
        lines.append("")
        
        # Count living organisms
        living_genomes = set()
        spawn_events = [e for e in lab_data if e.get("event_type") == "spawn"]
        
        for event in spawn_events:
            genome_id = event.get("genome_id")
            if genome_id:
                living_genomes.add(genome_id)
        
        # Remove death events
        death_events = [e for e in lab_data if e.get("event_type") in ["fitness_death", "boundary_death"]]
        for event in death_events:
            genome_id = event.get("genome_id")
            if genome_id in living_genomes:
                living_genomes.remove(genome_id)
        
        lines.append(f"**Total Living Organisms**: {len(living_genomes)}")
        lines.append("")
        
        # Culture distribution
        culture_dist = defaultdict(int)
        symbol_dist = defaultdict(int)
        
        for genome_id in living_genomes:
            if len(genome_id) >= 2:
                first_byte_hex = genome_id[:2]
                first_byte = int(first_byte_hex, 16)
                culture = LineagePoet._get_culture_name(first_byte)
                culture_dist[culture] += 1
        
        # Get symbol distribution from biome if available
        if biome and hasattr(biome, 'dishes'):
            for dish in biome.dishes.values():
                for organism in dish.organisms.values():
                    symbol = organism.state.anatomical_symbol
                    symbol_dist[symbol] += 1
        
        if culture_dist:
            lines.append("### Culture Distribution")
            for culture, count in sorted(culture_dist.items()):
                lines.append(f"- **{culture}**: {count}")
            lines.append("")
        
        if symbol_dist:
            lines.append("### Anatomical Archetype Distribution")
            archetype_names = {
                "â˜¿": "The Weaver (Social/Fluid)",
                "âš¥": "The Balanced (Versatile)",
                "âš²": "The Static (High-Speed/Efficient)",
                "â´²": "The Foundation (Storage/Protective)"
            }
            for symbol, count in sorted(symbol_dist.items()):
                name = archetype_names.get(symbol, symbol)
                lines.append(f"- **{symbol} {name}**: {count}")
            lines.append("")
        
        return lines
    
    def _section_phylogenetic_tree(self, lab_data: List[Dict]) -> List[str]:
        """Generate The Phylogenetic Tree section."""
        lines = []
        lines.append("## The Phylogenetic Tree (Names/Lineages)")
        lines.append("")
        
        # Build lineage tree
        spawn_events = [e for e in lab_data if e.get("event_type") == "spawn"]
        
        # Group by generation
        by_generation = defaultdict(list)
        for event in spawn_events:
            generation = event.get("generation", 0)
            genome_id = event.get("genome_id")
            scientific_name = event.get("scientific_name", "Unknown")
            parent_id = event.get("parent_id")
            
            if genome_id:
                by_generation[generation].append({
                    "genome_id": genome_id,
                    "name": scientific_name,
                    "parent_id": parent_id,
                    "event": event
                })
        
        # Display tree
        for generation in sorted(by_generation.keys()):
            lines.append(f"### Generation {generation}")
            lines.append("")
            
            for org in by_generation[generation]:
                name = org["name"]
                genome_id = org["genome_id"]
                
                # Generate name if missing
                if not name or name == "Unknown":
                    try:
                        name = LineagePoet.generate_name(genome_id)
                    except (ValueError, IndexError):
                        name = f"Organism-{genome_id[:8]}"
                
                genome_short = genome_id[:16] + "..."
                parent_short = org["parent_id"][:16] + "..." if org["parent_id"] else "None (Genesis)"
                
                lines.append(f"- **{name}**")
                lines.append(f"  - Genome: `{genome_short}`")
                lines.append(f"  - Parent: `{parent_short}`")
                
                # Check for conjugation
                payload = org["event"].get("payload", {})
                if payload.get("event") == "born_from_conjugation":
                    parent_a = payload.get("parent_a_name", "Unknown")
                    parent_b = payload.get("parent_b_name", "Unknown")
                    lines.append(f"  - **Hybrid**: Child of {parent_a} Ã— {parent_b}")
                
                lines.append("")
        
        return lines
    
    def _section_metabolic_health(self, lab_data: List[Dict], biome: Optional["Biome"]) -> List[str]:
        """Generate Metabolic Health section."""
        lines = []
        lines.append("## Metabolic Health")
        lines.append("")
        
        if not biome or not hasattr(biome, 'dishes'):
            lines.append("*Biome data not available*")
            return lines
        
        # Aggregate energy statistics
        total_energy = 0.0
        organism_count = 0
        energy_by_culture = defaultdict(list)
        
        for dish in biome.dishes.values():
            for organism in dish.organisms.values():
                energy = organism.state.energy
                total_energy += energy
                organism_count += 1
                
                # Group by culture
                if len(organism.genome_id) >= 2:
                    first_byte_hex = organism.genome_id[:2]
                    first_byte = int(first_byte_hex, 16)
                    culture = LineagePoet._get_culture_name(first_byte)
                    energy_by_culture[culture].append(energy)
        
        if organism_count > 0:
            avg_energy = total_energy / organism_count
            lines.append(f"**Average Energy**: {avg_energy:.2f}%")
            lines.append(f"**Total Organisms**: {organism_count}")
            lines.append("")
            
            if energy_by_culture:
                lines.append("### Energy by Culture")
                for culture, energies in sorted(energy_by_culture.items()):
                    avg = sum(energies) / len(energies) if energies else 0
                    lines.append(f"- **{culture}**: {avg:.2f}% (n={len(energies)})")
                lines.append("")
        else:
            lines.append("*No organisms in biome*")
        
        return lines
    
    def _section_breach_incidents(self, lab_data: List[Dict]) -> List[str]:
        """Generate Breach Incidents section."""
        lines = []
        lines.append("## Breach Incidents")
        lines.append("")
        
        breach_events = [
            e for e in lab_data 
            if (e.get("event_type") == "boundary_death" or 
                e.get("payload", {}).get("event") == "boundary_death")
        ]
        
        if not breach_events:
            lines.append("*No breach incidents recorded*")
            return lines
        
        lines.append(f"**Total Breaches**: {len(breach_events)}")
        lines.append("")
        
        for i, event in enumerate(breach_events[:10], 1):  # Limit to 10
            timestamp = event.get("timestamp", "Unknown")
            genome_id = event.get("genome_id", "Unknown")
            scientific_name = event.get("scientific_name", "Unknown")
            
            lines.append(f"### Breach #{i}")
            lines.append(f"- **Organism**: {scientific_name}")
            lines.append(f"- **Genome**: `{genome_id[:16]}...`")
            lines.append(f"- **Timestamp**: {timestamp}")
            lines.append("")
        
        if len(breach_events) > 10:
            lines.append(f"*... and {len(breach_events) - 10} more breaches*")
        
        return lines


class ObsidianGenerator:
    """
    Generator for Obsidian.md vault structure.
    
    Creates individual markdown files for each organism with YAML frontmatter,
    syncs journal entries (Thoughts and Reflections), and maintains an index.
    """
    
    def __init__(self, project_path: Path, observer: Optional[TheObserver] = None):
        """
        Initialize ObsidianGenerator.
        
        Args:
            project_path: Path to project root
            observer: TheObserver instance (creates if None)
        """
        self.project_path = Path(project_path)
        self.observer = observer or TheObserver(project_path=project_path)
        self.archive_path = self.project_path / "_pyrite" / "archive"
        self.archive_path.mkdir(parents=True, exist_ok=True)
    
    def generate_organism_file(self, organism: "BaseAgent") -> Path:
        """
        Generate Specimen_XX_Journal.md for an organism.
        
        Saves to both Obsidian_Archive/ and _pyrite/archive/ for binder printing.
        
        Args:
            organism: BaseAgent instance to document
            
        Returns:
            Path to created markdown file (primary path: Obsidian_Archive/)
        """
        from ..agent.base import BaseAgent
        
        # Extract specimen number from genome_id
        # Use last 2 hex chars of genome_id for XX (00-FF)
        genome_suffix = organism.genome_id[-2:]
        specimen_num = int(genome_suffix, 16) % 100  # 00-99
        specimen_id = f"Specimen_{specimen_num:02d}"
        
        filename = f"{specimen_id}_Journal.md"
        
        # Parse scientific name for content
        name_parts = LineagePoet.parse_name(organism.scientific_name)
        genus = name_parts.get("genus", "Unknown")
        species = name_parts.get("species", "Unknown")
        title = name_parts.get("title", "Unknown")
        culture = name_parts.get("culture", "Unknown")
        
        # Define paths for both locations
        obsidian_path = self.project_path / "Obsidian_Archive" / filename
        archive_path = self.archive_path / filename
        
        # Get parent/offspring links
        parent_link = None
        if organism.parent_id:
            # Find parent organism name
            parent_events = self._find_organism_events(organism.parent_id)
            if parent_events:
                parent_name = parent_events[0].get("scientific_name", "Unknown")
                parent_safe = parent_name.replace(",", "").replace(" ", "_")
                parent_link = f"[[{parent_safe}]]"
        
        # Find offspring (organisms with this as parent)
        offspring_links = []
        offspring_events = self._find_offspring_events(organism.genome_id)
        for event in offspring_events:
            child_name = event.get("scientific_name", "Unknown")
            child_safe = child_name.replace(",", "").replace(" ", "_")
            offspring_links.append(f"[[{child_safe}]]")
        
        # Build YAML frontmatter
        frontmatter = {
            "genome_id": organism.genome_id,
            "scientific_name": organism.scientific_name,
            "genus": genus,
            "species": species,
            "title": title,
            "culture": culture,
            "symbol": organism.state.anatomical_symbol,
            "archetype": organism.state.anatomical_archetype,
            "generation": organism.generation,
            "parent_id": organism.parent_id,
            "parent": parent_link,
            "offspring": offspring_links,
            "energy": organism.state.energy,
            "created": datetime.utcnow().isoformat()
        }
        
        # Build markdown content
        lines = []
        lines.append("---")
        for key, value in frontmatter.items():
            if isinstance(value, list):
                lines.append(f"{key}:")
                for item in value:
                    lines.append(f"  - {item}")
            else:
                lines.append(f"{key}: {value}")
        lines.append("---")
        lines.append("")
        lines.append(f"# {organism.scientific_name}")
        lines.append("")
        lines.append(f"**Symbol**: {organism.state.anatomical_symbol} {organism.state.anatomical_archetype}")
        lines.append(f"**Culture**: {culture}")
        lines.append(f"**Generation**: {organism.generation}")
        lines.append("")
        
        # Lineage section
        if parent_link:
            lines.append("## Lineage")
            lines.append(f"**Parent**: {parent_link}")
            lines.append("")
        
        if offspring_links:
            lines.append("## Offspring")
            for link in offspring_links:
                lines.append(f"- {link}")
            lines.append("")
        
        # Journal section (Thoughts and Reflections)
        lines.append("## Private Journal")
        lines.append("")
        
        if organism.state.journal:
            for entry in organism.state.journal[-20:]:  # Last 20 entries
                entry_type = entry.get("type", "Unknown")
                timestamp = entry.get("timestamp", "Unknown")
                
                if entry_type == "Thought":
                    lines.append(f"### ðŸ’­ Thought - {timestamp}")
                    if "content" in entry:
                        # Memory injection content
                        lines.append(f"{entry['content']}")
                    elif "context" in entry:
                        # Regular thought context
                        lines.append(f"**Context**: {entry['context']}")
                    if "state_snapshot" in entry:
                        lines.append(f"**State**: Energy={entry['state_snapshot'].get('energy', 'N/A')}")
                    lines.append("")
                
                elif entry_type == "Reflection":
                    lines.append(f"### ðŸ”„ Reflection - {timestamp}")
                    if "action_result" in entry:
                        lines.append(f"**Action**: {entry['action_result']}")
                    if "reflection_result" in entry:
                        reflection_text = str(entry['reflection_result'])
                        lines.append(f"**Reflection**: {reflection_text}")
                    lines.append("")
        else:
            lines.append("*No journal entries yet*")
            lines.append("")
        
        # Generate content
        content = "\n".join(lines)
        
        # Write to BOTH locations
        obsidian_path.parent.mkdir(parents=True, exist_ok=True)
        archive_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(obsidian_path, "w", encoding="utf-8") as f:
            f.write(content)
        
        with open(archive_path, "w", encoding="utf-8") as f:
            f.write(content)
        
        return obsidian_path  # Return primary path
    
    def generate_index(self, biome: Optional["Biome"] = None) -> Path:
        """
        Generate 00_Index.md with current population census.
        
        Args:
            biome: Optional Biome instance for current state
            
        Returns:
            Path to index file
        """
        index_path = self.archive_path / "00_Index.md"
        
        lines = []
        lines.append("# The Obsidian Archive - Population Census")
        lines.append("")
        lines.append(f"**Last Updated**: {datetime.utcnow().isoformat()}")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Load all organisms from laboratory data
        lab_data = self._load_laboratory_data()
        
        # Get living organisms
        living_genomes = set()
        spawn_events = [e for e in lab_data if e.get("event_type") == "spawn"]
        
        for event in spawn_events:
            genome_id = event.get("genome_id")
            if genome_id:
                living_genomes.add(genome_id)
        
        # Remove death events
        death_events = [e for e in lab_data if e.get("event_type") in ["fitness_death", "boundary_death", "death"]]
        for event in death_events:
            genome_id = event.get("genome_id")
            if genome_id in living_genomes:
                living_genomes.remove(genome_id)
        
        lines.append(f"## Current Population: {len(living_genomes)}")
        lines.append("")
        
        # Group by generation
        by_generation = defaultdict(list)
        for genome_id in living_genomes:
            # Find spawn event for this genome
            spawn_event = next((e for e in spawn_events if e.get("genome_id") == genome_id), None)
            if spawn_event:
                generation = spawn_event.get("generation", 0)
                scientific_name = spawn_event.get("scientific_name", "Unknown")
                if not scientific_name or scientific_name == "Unknown":
                    try:
                        scientific_name = LineagePoet.generate_name(genome_id)
                    except:
                        scientific_name = f"Organism-{genome_id[:8]}"
                
                by_generation[generation].append({
                    "genome_id": genome_id,
                    "name": scientific_name
                })
        
        # Display by generation
        for generation in sorted(by_generation.keys()):
            lines.append(f"### Generation {generation}")
            lines.append("")
            
            for org in by_generation[generation]:
                safe_name = org["name"].replace(",", "").replace(" ", "_")
                lines.append(f"- [[{safe_name}]] - `{org['genome_id'][:16]}...`")
            
            lines.append("")
        
        # Culture distribution
        culture_dist = defaultdict(int)
        for genome_id in living_genomes:
            if len(genome_id) >= 2:
                first_byte_hex = genome_id[:2]
                first_byte = int(first_byte_hex, 16)
                culture = LineagePoet._get_culture_name(first_byte)
                culture_dist[culture] += 1
        
        if culture_dist:
            lines.append("## Culture Distribution")
            lines.append("")
            for culture, count in sorted(culture_dist.items()):
                lines.append(f"- **{culture}**: {count}")
            lines.append("")
        
        # Write index
        with open(index_path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        
        return index_path
    
    def _load_laboratory_data(self) -> List[Dict]:
        """Load all events from laboratory.jsonl."""
        lab_file = self.project_path / "_pyrite" / "science" / "laboratory.jsonl"
        
        if not lab_file.exists():
            return []
        
        events = []
        with open(lab_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        event = json.loads(line)
                        events.append(event)
                    except json.JSONDecodeError:
                        continue
        
        return events
    
    def _find_organism_events(self, genome_id: str) -> List[Dict]:
        """Find all events for a specific genome_id."""
        lab_data = self._load_laboratory_data()
        return [e for e in lab_data if e.get("genome_id") == genome_id]
    
    def _find_offspring_events(self, parent_genome_id: str) -> List[Dict]:
        """Find all spawn events where parent_id matches."""
        lab_data = self._load_laboratory_data()
        spawn_events = [e for e in lab_data if e.get("event_type") == "spawn"]
        return [e for e in spawn_events if e.get("parent_id") == parent_genome_id]
    
    def sync_all_organisms(self, biome: "Biome") -> List[Path]:
        """
        Sync all organisms in biome to Obsidian files.
        
        Args:
            biome: Biome instance containing organisms
            
        Returns:
            List of created/updated file paths
        """
        paths = []
        
        for dish in biome.dishes.values():
            for organism in dish.organisms.values():
                file_path = self.generate_organism_file(organism)
                paths.append(file_path)
        
        # Generate index
        index_path = self.generate_index(biome)
        paths.append(index_path)
        
        return paths
